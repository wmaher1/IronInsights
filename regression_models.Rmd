---
title: "Regression Models"
author: "Will Maher"
date: "2024-04-30"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(glmnet)
library(naniar)
library(RANN)
library(caret)
```

```{r}
pwr <- readRDS("pwrlift.rds") %>% 
    mutate(across(where(is.character), as.factor))

training <- pwr %>% 
    filter(year == 2023) %>%
    select(-c(year, name)) 

validation <- pwr %>%
    filter(year == 2024) %>%
    select(-c(year, name)) 

```

This RDS file contains only data from raw lifters competing in the USAPL federation. Additionally, it only contains relevant variables and removed observations where a lifter failed to complete all three attempts at any of the three lifts.

We will use 2023 data as training data and 2024 data as validation data. There are fewer observations in the validation data set, but it is not too extreme. 


```{r imputation}
training <- as.data.frame(training)
test = preProcess(training %>% select(-c(div, total)), method = "knnImpute") # remove total and division (too many levels)
train.imp <- predict(test, training)
vars.na <- train.imp %>% select_if(colSums(is.na(.))>0) %>% names
vars.na
missprop<-train.imp %>% summarise(across(everything(), ~ sum(is.na(.))/length(.)))
print(missprop)


validation <- as.data.frame(validation)
validation.imp <- predict(test, validation)
vars.na <- validation.imp %>% select_if(colSums(is.na(.))>0) %>% names
vars.na
missprop <- validation.imp %>% summarise(across(everything(), ~ sum(is.na(.))/length(.)))
print(missprop)
```



```{r linear}
linear.mdl <- lm(total ~ squat1 + bench1 + pull1 + I(weight*age), training)
summary(linear.mdl)

linear.mdl2 <- lm(total ~ squat1 + bench1 + pull1, training)
summary(linear.mdl2)
```


```{r lasso}
x <- data.matrix(train.imp[,c('squat1', 'bench1', 'pull1',
                              'squat2', 'bench2', 'pull2', 
                              'div', 'weight', 'sex')])

y <- train.imp$total

# k fold cv for optimal lambda
cv_model <- cv.glmnet(x, y, alpha = 1)
best_lambda <- cv_model$lambda.min

plot(cv_model)

final_lasso <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(final_lasso)
```


```{r ridge}
x <- data.matrix(train.imp[,c('squat1', 'bench1', 'pull1',
                              'squat2', 'bench2', 'pull2', 
                              'div', 'weight', 'sex')])
y

lambda_seq <- 10^seq(2, -2, by = -.1)
ridge_fit <- glmnet(x, y, alpha = 0, lambda = lambda_seq)

# k fold cv for optimal lambda
ridge_cv <- cv.glmnet(x, y, alpha = 0, lambda = lambda_seq)
best_lambda_ridge <- ridge_cv$lambda.min

plot(ridge_cv)

best_fit_ridge <- ridge_cv$glmnet.fit
#head(best_fit_ridge)

final_ridge <- glmnet(x, y, alpha = 0, lambda = best_lambda_ridge)
coef(final_ridge)
# look into significance
```


```{r}
pred.linear <- predict(linear.mdl, newdata = validation)
actual <- validation$total

mse.linear <- mean((pred.linear - actual)^2)
mse.linear
```



```{r}
x_test <- data.matrix(validation.imp[,c('squat1', 'bench1', 'pull1',
                              'squat2', 'bench2', 'pull2', 
                              'div', 'weight', 'sex')])

pred.lasso <- predict(final_lasso, newx = x_test)
actual <- validation.imp$total

mse.lasso <- mean((pred.lasso - actual)^2)
mse.lasso

sse.lasso <- sum((pred.lasso - actual)^2)
sst <- sum((actual - mean(actual))^2)

1 - (sse.lasso / sst)
```


```{r}
x_test <- data.matrix(validation.imp[,c('squat1', 'bench1', 'pull1',
                                    'squat2', 'bench2', 'pull2', 
                                    'div', 'weight', 'sex')])

pred.ridge <- predict(final_ridge, newx = x_test)
actual <- validation.imp$total

mse.ridge <- mean((pred.ridge - actual)^2)
mse.ridge

sse.ridge <- sum((pred.ridge - actual)^2)
sst <- sum((actual - mean(actual))^2)

1 - (sse.ridge/sst)

```


```{r}
df <- data.frame(pred.ridge = pred.ridge, actual = actual)

# Create the plot
ggplot(df, aes(x = pred.ridge, y = actual)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = coef(lm(actual ~ pred.ridge))[1], slope = coef(lm(actual ~ pred.ridge))[2], color = "red") +
  labs(x = "Predicted Total", y = "Actual Total", title = "Ridge Predicted vs Actual") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_minimal()
```


```{r}
df2 <- data.frame(pred.lasso = pred.lasso, actual = actual)

ggplot(df, aes(x = pred.lasso, y = actual)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = coef(lm(actual ~ pred.lasso))[1], slope = coef(lm(actual ~ pred.lasso))[2], color = "red") +
  labs(x = "Predicted Total", y = "Actual Total", title = "Lasso Predicted vs Actual") +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_minimal()
```

